{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ce1863275e6f7c9dd6bb1a85e9be673",
     "grade": false,
     "grade_id": "cell-c62a654b63bcc6a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Lab 3\n",
    "\n",
    "In the previous labs, we perform mortality prediction based on the last visit's diagnosis codes using DNN. This practice igrnoes massive information in the previous visits of a patient. Thus, Starting from this lab, we will play with sequential visit data. That is, each patient will have a sequence of visists. \n",
    "\n",
    "However, MLP is quite unsatisfying when dealing with such rich structure data. This lab introduces convolutional neural networks (CNNs), a powerful family of neural networks that are designed for precisely this purpose.\n",
    "\n",
    "Table of Contents:\n",
    "- Convolutions for Images\n",
    "- Padding and Stride\n",
    "- Pooling\n",
    "- Assignment\n",
    "\n",
    "Some contents of this lab are adapted from [Dive into Deep Learning](https://d2l.ai) and [Official PyTorch Tutorials](https://pytorch.org/tutorials/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.132823Z",
     "start_time": "2021-12-10T04:02:11.129993Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ec96802e337ce0700f6db56afa5efbc",
     "grade": false,
     "grade_id": "cell-6fb60e1a98394fe2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.138646Z",
     "start_time": "2021-12-10T04:02:11.135043Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dfe8ed43a3f5980a3c92360d617e4e4",
     "grade": false,
     "grade_id": "cell-204b53e7b414910c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 24\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these lines set the seed for different random number generators, so that your code will produce the same results every time you run it—helpful for debugging and sharing experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.261670Z",
     "start_time": "2021-12-10T04:02:11.140607Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2d820e50d980d5cd85e747cee3ca331",
     "grade": false,
     "grade_id": "cell-120c0ecf94034038",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv\r\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../LAB3-lib/data\"\n",
    "assert os.path.isdir(DATA_PATH)\n",
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96480855a5b84fd9eab5e0424029a4a2",
     "grade": false,
     "grade_id": "cell-e7a788c7628625ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Convolution Operation\n",
    "\n",
    "Though we will deal with sequential data (1D) in the assignment. Let us first start with some images data (2D) to \n",
    "build out intuition. \n",
    "\n",
    "Convolutional neural networks are efficient architectures for exploring structure in image data.\n",
    "\n",
    "Convolution operation take an input tensor and a kernel tensor and produce an output tensor through convolution operation. Let us ignore channels for now and see how this works with two-dimensional data and hidden representations. In the figure below, the input is a two-dimensional tensor with a height of 3 and width of 3. We mark the shape of the tensor as 3x3 or (3, 3). The height and width of the kernel are both 2. The shape of the kernel window (or convolution window) is given by the height and width of the kernel (here it is 2x2).\n",
    "\n",
    "<img src='./img/convolution.svg'>\n",
    "\n",
    "In the two-dimensional cross-correlation operation, we begin with the convolution window positioned at the top-left corner of the input tensor and slide it across the input tensor, both from left to right and top to bottom. When the convolution window slides to a certain position, the input subtensor contained in that window and the kernel tensor are multiplied elementwise and the resulting tensor is summed up yielding a single scalar value. This result gives the value of the output tensor at the corresponding location. Here, the output tensor has a height of 2 and width of 2 and the four elements are derived from the two-dimensional cross-correlation operation:\n",
    "\n",
    "$$\n",
    "\\begin{split}0\\times0+1\\times1+3\\times2+4\\times3=19,\\\\\n",
    "1\\times0+2\\times1+4\\times2+5\\times3=25,\\\\\n",
    "3\\times0+4\\times1+6\\times2+7\\times3=37,\\\\\n",
    "4\\times0+5\\times1+7\\times2+8\\times3=43.\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Explanation\n",
    "Sure! Here’s an explanation for a curious kid:\n",
    "\n",
    "---\n",
    "\n",
    "**Imagine you have a small picture made up of numbers in a grid, like this:**\n",
    "\n",
    "```\n",
    "0 1 2\n",
    "3 4 5\n",
    "6 7 8\n",
    "```\n",
    "\n",
    "**You also have a tiny \"window\" (called a kernel), like this:**\n",
    "\n",
    "```\n",
    "0 1\n",
    "2 3\n",
    "```\n",
    "\n",
    "**The job of a convolution operation is to slide this tiny window over your big grid, and at every spot, it mixes the numbers together in a special way. Here’s how it works:**\n",
    "\n",
    "1. **Put the tiny window on the top-left corner of the big grid.**\n",
    "2. **Multiply each number in the window by the number it covers in the grid.**\n",
    "3. **Add all those results together to get one new number.**\n",
    "4. **Move the window one step to the right, do it again, and then down—until you’ve covered the whole grid!**\n",
    "\n",
    "**For example, at the top-left:**\n",
    "\n",
    "- Window covers: 0, 1, 3, 4\n",
    "- Kernel numbers: 0, 1, 2, 3\n",
    "- Multiply: (0×0), (1×1), (3×2), (4×3)\n",
    "- Add: 0 + 1 + 6 + 12 = **19**\n",
    "\n",
    "**You do this at four spots, and collect four new numbers into a new, smaller grid.**\n",
    "\n",
    "**This is how computers use convolution to “look at” pictures and find patterns, like shapes or edges, step by step. It’s like sliding a tiny magnifying glass over a photo and writing down what you see at each spot!**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2b2a67dd4cbc81f69ba8f1589fbe4b1",
     "grade": false,
     "grade_id": "cell-4a73c276a3b5a068",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 1 [10 points]\n",
    "\n",
    "Calculate the output shape for a convolutional layer: given the input tensor shape $(n_w, n_h)$, the kernel tensor shape $(k_w, k_h)$, calculate the output tensor shape. For example, the output shape for the figure above is $(2, 2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.266735Z",
     "start_time": "2021-12-10T04:02:11.263685Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def conv_output_shape_1(n_w, n_h, k_w, k_h):\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: Calculate the output tensor shape.\n",
    "    Note the output should a tuple with two elements (width, height). \n",
    "    \"\"\"\n",
    "    output_width = n_w - k_w + 1\n",
    "    output_height = n_h - k_h + 1\n",
    "    #raise NotImplementedError\n",
    "    return (output_width, output_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time you move the kernel across the input, you need to make sure the whole kernel fits inside. The formula tells you how many places it can fit horizontally and vertically, giving you the size of the output.\n",
    "\n",
    "In summary:\n",
    "\n",
    "    The formula calculates how many times you can slide the kernel over the input, and that’s exactly the number of output values you get—just like in the example!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.272511Z",
     "start_time": "2021-12-10T04:02:11.269268Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9be534d4228b758bf0a84533777bd033",
     "grade": true,
     "grade_id": "cell-3cf0291efe3340a9",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert conv_output_shape_1(n_w=7, n_h=7, k_w=3, k_h=3) == (5, 5)\n",
    "assert conv_output_shape_1(n_w=7, n_h=9, k_w=4, k_h=2) == (4, 8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What if the stride was more than 1?\n",
    "\n",
    "If the stride is bigger (like stride=2), the positions are farther apart, and the formula changes to:\n",
    "output_width = floor((n_w - k_w) / stride) + 1\n",
    "\n",
    "But for stride=1, the simple +1 counts every position the kernel can fit.\n",
    "\n",
    "In summary:\n",
    "The +1 makes sure you count every position starting from the very first to the very last, only for stride=1!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe87a84e27bf38c181cf79c5723bb328",
     "grade": false,
     "grade_id": "cell-40d58ffd6353d1ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 2 [10 points]\n",
    "\n",
    "Implement the 2D convolution function, which accepts an input tensor X and a kernel tensor K and returns an output tensor Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.277255Z",
     "start_time": "2021-12-10T04:02:11.273876Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    \"\"\" TODO: Compute 2D convolution. \"\"\"\n",
    "    # your code here\n",
    "    h, w = K.shape\n",
    "    out_h = X.shape[0] - h + 1\n",
    "    out_w = X.shape[1] - w + 1\n",
    "    Y = torch.zeros((out_h, out_w))\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            Y[i, j] = (X[i:i+h, j:j+w] * K).sum()\n",
    "    return Y\n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.283631Z",
     "start_time": "2021-12-10T04:02:11.278764Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed053dafa7288f5f34b317a80b275d64",
     "grade": true,
     "grade_id": "cell-00293bf4adfd6c5c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "assert torch.allclose(corr2d(X, K), torch.tensor([[19., 25.], [37., 43.]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple explanation\n",
    "Absolutely! Let’s walk through how `corr2d(X, K)` works step by step with your example.\n",
    "\n",
    "### **Input tensors**\n",
    "```python\n",
    "import torch\n",
    "\n",
    "X = torch.tensor([[0.0, 1.0, 2.0],\n",
    "                  [3.0, 4.0, 5.0],\n",
    "                  [6.0, 7.0, 8.0]])\n",
    "\n",
    "K = torch.tensor([[0.0, 1.0],\n",
    "                  [2.0, 3.0]])\n",
    "```\n",
    "\n",
    "### **How Corr2D computes the output**\n",
    "\n",
    "#### 1. **Kernel shape**  \n",
    "K is 2×2.\n",
    "\n",
    "#### 2. **Output shape**  \n",
    "- Output height: 3 - 2 + 1 = 2  \n",
    "- Output width: 3 - 2 + 1 = 2  \n",
    "So output will be 2×2.\n",
    "\n",
    "#### 3. **Sliding and calculation**\n",
    "\n",
    "**Position (0, 0):**  \n",
    "Cover X[0:2, 0:2] =  \n",
    "```\n",
    "[[0, 1],\n",
    " [3, 4]]\n",
    "```\n",
    "Multiply elementwise by K:  \n",
    "```\n",
    "[[0×0, 1×1],\n",
    " [3×2, 4×3]] = [0, 1, 6, 12]\n",
    "```\n",
    "Sum: 0 + 1 + 6 + 12 = **19**\n",
    "\n",
    "---\n",
    "\n",
    "**Position (0, 1):**  \n",
    "Cover X[0:2, 1:3] =  \n",
    "```\n",
    "[[1, 2],\n",
    " [4, 5]]\n",
    "```\n",
    "Multiply:  \n",
    "```\n",
    "[[1×0, 2×1],\n",
    " [4×2, 5×3]] = [0, 2, 8, 15]\n",
    "```\n",
    "Sum: 0 + 2 + 8 + 15 = **25**\n",
    "\n",
    "---\n",
    "\n",
    "**Position (1, 0):**  \n",
    "Cover X[1:3, 0:2] =  \n",
    "```\n",
    "[[3, 4],\n",
    " [6, 7]]\n",
    "```\n",
    "Multiply:  \n",
    "```\n",
    "[[3×0, 4×1],\n",
    " [6×2, 7×3]] = [0, 4, 12, 21]\n",
    "```\n",
    "Sum: 0 + 4 + 12 + 21 = **37**\n",
    "\n",
    "---\n",
    "\n",
    "**Position (1, 1):**  \n",
    "Cover X[1:3, 1:3] =  \n",
    "```\n",
    "[[4, 5],\n",
    " [7, 8]]\n",
    "```\n",
    "Multiply:  \n",
    "```\n",
    "[[4×0, 5×1],\n",
    " [7×2, 8×3]] = [0, 5, 14, 24]\n",
    "```\n",
    "Sum: 0 + 5 + 14 + 24 = **43**\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Output**\n",
    "So, `corr2d(X, K)` will return:\n",
    "```\n",
    "[[19, 25],\n",
    " [37, 43]]\n",
    "```\n",
    "\n",
    "### **In Code**\n",
    "```python\n",
    "output = torch.tensor([[19., 25.],\n",
    "                      [37., 43.]])\n",
    "```\n",
    "\n",
    "This matches the expected result!\n",
    "\n",
    "**Let me know if you want to see the actual `corr2d` implementation in code!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cbd077f553c7f733074f8f2245c6a7a9",
     "grade": false,
     "grade_id": "cell-b2f57cdb1e9cb59d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Padding and Stride\n",
    "\n",
    "In several cases, we incorporate techniques, including padding and strided convolutions, that affect the size of the output. As motivation, note that since kernels generally have width and height greater than 1, after applying many successive convolutions, we tend to wind up with outputs that are considerably smaller than our input. If we start with a 240×240 pixel image, 10 layers of 5x5 convolutions reduce the image to 200×200 pixels, slicing off 30%\n",
    "of the image and with it obliterating any interesting information on the boundaries of the original image. Padding is the most popular tool for handling this issue.\n",
    "\n",
    "In other cases, we may want to reduce the dimensionality drastically, e.g., if we find the original input resolution to be unwieldy. Strided convolutions are a popular technique that can help in these instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "878e1aa494da4c400ae4ddee80b13fb4",
     "grade": false,
     "grade_id": "cell-e4cbe1af43117fca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1 Padding\n",
    "\n",
    "As described above, one tricky issue when applying convolutional layers is that we tend to lose pixels on the perimeter of our image. Since we typically use small kernels, for any given convolution, we might only lose a few pixels, but this can add up as we apply many successive convolutional layers. One straightforward solution to this problem is to add extra pixels of filler around the boundary of our input image, thus increasing the effective size of the image. Typically, we set the values of the extra pixels to zero. In the figure below, we pad a 3×3 input, increasing its size to 5×5. The corresponding output then increases to a 4×4 matrix. The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation: 0×0+0×1+0×2+0×3=0.\n",
    "\n",
    "<img src='./img/conv-pad.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f49b6caecf632c4e1afd17f975733281",
     "grade": false,
     "grade_id": "cell-d953b18f84a624b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Stride\n",
    "\n",
    "When computing the convolution, we start with the convolution window at the top-left corner of the input tensor, and then slide it over all locations both down and to the right. In previous examples, we default to sliding one element at a time. However, sometimes, either for computational efficiency or because we wish to downsample, we move our window more than one element at a time, skipping the intermediate locations.\n",
    "\n",
    "We refer to the number of rows and columns traversed per slide as the stride. So far, we have used strides of 1, both for height and width. Sometimes, we may want to use a larger stride. The figure below shows a two-dimensional convolution operation with a stride of 3 vertically and 2 horizontally. The shaded portions are the output elements as well as the input and kernel tensor elements used for the output computation:  0×0+0×1+1×2+2×3=8, 0×0+6×1+0×2+0×3=6. We can see that when the second element of the first column is outputted, the convolution window slides down three rows. The convolution window slides two columns to the right when the second element of the first row is outputted. When the convolution window continues to slide two columns to the right on the input, there is no output because the input element cannot fill the window (unless we add another column of padding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply explained:\n",
    "\n",
    "Padding and Stride in Convolutions — Explained Simply\n",
    "\n",
    "Imagine you have a big picture made of numbers, like a giant grid. When you use a small window (the kernel) to look at this picture and do math, sometimes the edges of the picture get left out and disappear as you do this over and over.\n",
    "Padding\n",
    "\n",
    "    Padding is like putting a frame of zeros around your picture.\n",
    "    If your picture is too small, you add extra empty squares around the edges so your window can fit and look at every part of the picture.\n",
    "    This way, you don’t lose the edge pieces when you slide your window!\n",
    "\n",
    "Why do we need padding?\n",
    "\n",
    "    If you keep using your window without padding, your picture shrinks and you lose important information near the edges.\n",
    "    Padding helps keep the picture big and keeps all the information, even after many steps.\n",
    "\n",
    "Stride\n",
    "\n",
    "    Stride is how many steps your window moves each time.\n",
    "    If stride is 1, your window moves just one square at a time.\n",
    "    If stride is bigger, like 2 or 3, your window jumps ahead by 2 or 3 squares each time.\n",
    "    This means you get fewer results, and your answer grid is smaller.\n",
    "\n",
    "Why use a bigger stride?\n",
    "\n",
    "    Sometimes, your picture is so big it’s hard to work with, so you use a bigger stride to make your work easier and faster.\n",
    "    It’s like skipping spaces when you walk, so you get across the room quicker!\n",
    "\n",
    "Summary:\n",
    "Padding helps you keep the edges of your picture safe.\n",
    "Stride lets you move your window faster and shrink the result.\n",
    "Both are ways to control how you look at pictures with computers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40e98bd48f6eaf8e751a54708de58594",
     "grade": false,
     "grade_id": "cell-9972bce032bdc90d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 3 [10 points]\n",
    "\n",
    "Calculate the output shape for a convolutional layer with padding: given the input tensor shape $(n_w, n_h)$, the kernel tensor shape $(k_w, k_h)$, padding size $(p_w, p_h)$, stride size $(s_w, s_h)$, calculate the output tensor shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.288359Z",
     "start_time": "2021-12-10T04:02:11.285281Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def conv_output_shape_2(n_w, n_h, k_w, k_h, p_w, p_h, s_w, s_h):\n",
    "    \n",
    "    \"\"\"\n",
    "    TODO: Calculate the output tensor shape.\n",
    "    Note the output should a tuple with two elements (width, height). \n",
    "    \"\"\"\n",
    "    # your code here\n",
    "    output_width = (n_w + 2*p_w - k_w) // s_w + 1\n",
    "    output_height = (n_h + 2*p_h - k_h) // s_h + 1\n",
    "    return (output_width, output_height)\n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.294885Z",
     "start_time": "2021-12-10T04:02:11.290222Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d049a8cffa5a6188db350a0d4430212b",
     "grade": true,
     "grade_id": "cell-99a12d5208d4d7d6",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert conv_output_shape_2(n_w=7, n_h=7, k_w=3, k_h=3, p_w=1, p_h=1, s_w=1, s_h=1) == (7, 7)\n",
    "assert conv_output_shape_2(n_w=7, n_h=7, k_w=3, k_h=3, p_w=0, p_h=0, s_w=2, s_h=2) == (3, 3)\n",
    "assert conv_output_shape_2(n_w=7, n_h=9, k_w=4, k_h=2, p_w=0, p_h=1, s_w=2, s_h=1) == (2, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb11b5b6d5e666c3ec493a79440c1724",
     "grade": false,
     "grade_id": "cell-db2171adeaa11955",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. Multiple Input and Multiple Output Channels\n",
    "\n",
    "Denote by $c_i$ and $c_o$ the number of input and output channels, respectively, and let $k_h$ and $k_w$ be the height and width of the kernel. To get an output with multiple channels, we can create a kernel tensor of shape $c_i \\times k_h \\times k_w$ for every output channel. We concatenate them on the output channel dimension, so that the shape of the convolution kernel is $c_o \\times c_i \\times k_h \\times k_w$. In convolution operations, the result on each output channel is calculated from the convolution kernel corresponding to that output channel and takes input from all channels in the input tensor.\n",
    "\n",
    "<img src='./img/conv-channel.svg'>\n",
    "\n",
    "In the figure above, the number of input and output channels are 3 and 2. And there are $2 \\times 3$ sets of kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Input and Multiple Output Channels — Like Making a Fancy Sandwich!\n",
    "\n",
    "Imagine you’re making a sandwich, but instead of just bread and cheese, you have three layers of yummy stuff inside (like peanut butter, jelly, and bananas). Each layer is a “channel.”\n",
    "Input Channels\n",
    "\n",
    "    Think of a picture with three versions stacked up—like a color photo made of red, green, and blue layers.\n",
    "    These are your input channels. (For example: 3 channels.)\n",
    "\n",
    "Output Channels\n",
    "\n",
    "    Now, imagine you want to make TWO different kinds of sandwiches from those layers—maybe one with extra peanut butter and one with extra jelly.\n",
    "    These are your output channels. (For example: 2 channels.)\n",
    "\n",
    "Kernels — The Recipe\n",
    "\n",
    "    For each output sandwich, you need a special recipe (kernel) that tells you how to mix and match the layers from your input.\n",
    "    If you have 3 input channels and want 2 output channels, you need 2 × 3 = 6 recipes (kernels)!\n",
    "    Each output channel gets its own set of recipes to create a new layer from all the input layers.\n",
    "\n",
    "How Does It Work?\n",
    "\n",
    "    To make the first output sandwich, you use three recipes—one for peanut butter, one for jelly, one for bananas—and mix them together.\n",
    "    To make the second output sandwich, you do the same but with different recipes.\n",
    "    You end up with two new sandwich layers (output channels), each made from all the input layers using their own special mixing rules.\n",
    "\n",
    "In short:\n",
    "If your input is made of three layers and you want to make two different new layers, you need a separate set of recipes for each output layer, using all the input layers every time. That’s how computers mix information from different channels to create new “pictures”!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4c5e51b1cec69e0adec08a4692d96ad",
     "grade": false,
     "grade_id": "cell-d739af556c00535d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4. Pooling\n",
    "\n",
    "Often, as we process images, we want to gradually reduce the spatial resolution of our hidden representations, aggregating information so that the higher up we go in the network, the larger the receptive field (in the input) to which each hidden node is sensitive.\n",
    "\n",
    "Like convolutional layers, pooling operators consist of a fixed-shape window that is slid over all regions in the input according to its stride, computing a single output for each location traversed by the fixed-shape window (sometimes known as the pooling window). However, unlike the cross-correlation computation of the inputs and kernels in the convolutional layer, the pooling layer contains no parameters (there is no kernel). Instead, pooling operators are deterministic, typically calculating either the maximum or the average value of the elements in the pooling window. These operations are called maximum pooling (max pooling for short) and average pooling, respectively.\n",
    "\n",
    "In both cases, as with the cross-correlation operator, we can think of the pooling window as starting from the upper-left of the input tensor and sliding across the input tensor from left to right and top to bottom. At each location that the pooling window hits, it computes the maximum or average value of the input subtensor in the window, depending on whether max or average pooling is employed.\n",
    "\n",
    "<img src='./img/pooling.svg'>\n",
    "\n",
    "The output tensor in the figure above has a height of 2 and a width of 2. The four elements are derived from the maximum value in each pooling window:\n",
    "\n",
    "$$\n",
    "\\begin{split}\\max(0, 1, 3, 4)=4,\\\\\n",
    "\\max(1, 2, 4, 5)=5,\\\\\n",
    "\\max(3, 4, 6, 7)=7,\\\\\n",
    "\\max(4, 5, 7, 8)=8.\\\\\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maxpooling simplified:\n",
    "\n",
    "Here's a kid-friendly explanation of pooling in pictures and neural networks:\n",
    "Pooling — Like Picking the Best (or Average) in Each Group!\n",
    "\n",
    "Imagine you have a big grid of numbers, like a game board. You want to make the grid smaller, but you still want to keep the most important parts!\n",
    "How does pooling work?\n",
    "\n",
    "    You use a small window (like a 2×2 square) and slide it over your big grid, one step at a time.\n",
    "    At each spot, you only keep one number for that window.\n",
    "\n",
    "Max Pooling\n",
    "\n",
    "    For each window, you look at all the numbers inside, and you pick the biggest one.\n",
    "    So if your window covers the numbers [0, 1, 3, 4], you keep 4 because it's the biggest.\n",
    "    You do this for every window, and you build a new, smaller grid with just those biggest numbers!\n",
    "\n",
    "Average Pooling\n",
    "\n",
    "    Instead of picking the biggest, you add up all the numbers in the window and divide by how many there are.\n",
    "    So if your window covers [0, 1, 3, 4], you add them up (0+1+3+4=8) and divide by 4, so you keep 2.\n",
    "\n",
    "Why do we use pooling?\n",
    "\n",
    "    Pooling helps shrink your grid so your computer has less to look at.\n",
    "    It also helps keep the most important information, even when the grid gets smaller.\n",
    "\n",
    "Example:\n",
    "\n",
    "If you have this grid:\n",
    "Code\n",
    "\n",
    "0 1 2\n",
    "3 4 5\n",
    "6 7 8\n",
    "\n",
    "and you use max pooling with a 2×2 window, you get:\n",
    "Code\n",
    "\n",
    "4 5\n",
    "7 8\n",
    "\n",
    "Because those are the biggest numbers in each window!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7ca267c604aaa00b16a086583f5d3d9",
     "grade": false,
     "grade_id": "cell-e873bdd6653b39c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Exercise 4 [10 points]\n",
    "\n",
    "Implement a 2D max pooling layer from scratch, which accepts an input tensor X and pool size and returns an output tensor Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.300692Z",
     "start_time": "2021-12-10T04:02:11.296927Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def maxpool2d(X, pool_size):\n",
    "    # your code here\n",
    "    h, w = pool_size\n",
    "    out_h = X.shape[0] - h + 1\n",
    "    out_w = X.shape[1] - w + 1\n",
    "    Y = torch.zeros((out_h, out_w))\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "            Y[i, j] = X[i:i+h, j:j+w].max()\n",
    "    return Y\n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.311880Z",
     "start_time": "2021-12-10T04:02:11.305965Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f35aa399e9044796e506ce2da9f6f971",
     "grade": true,
     "grade_id": "cell-ebbbed2cb92d5ff1",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "assert torch.allclose(maxpool2d(X, (2, 2)), torch.tensor([[4., 5.], [7., 8.]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absolutely! Here’s a **line-by-line explanation** of your `maxpool2d` function:\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "def maxpool2d(X, pool_size):\n",
    "```\n",
    "- **Defines** a function named `maxpool2d` that takes:\n",
    "  - `X`: a 2D tensor (like a grid of numbers, such as an image)\n",
    "  - `pool_size`: a tuple (height, width) that tells you the size of the pooling window.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "    h, w = pool_size\n",
    "```\n",
    "- **Unpacks** the pool size tuple into `h` (window height) and `w` (window width).\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "    out_h = X.shape[0] - h + 1\n",
    "    out_w = X.shape[1] - w + 1\n",
    "```\n",
    "- **Calculates** the size of the output tensor:\n",
    "  - `out_h`: number of rows in the output grid.\n",
    "    - `X.shape[0]` is the number of rows in `X`.\n",
    "    - By subtracting the window height and adding 1, you get the number of places your window can slide down.\n",
    "  - `out_w`: number of columns in the output grid.\n",
    "    - Same logic, using columns and window width.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "    Y = torch.zeros((out_h, out_w))\n",
    "```\n",
    "- **Creates a new tensor** `Y` of zeros with the shape of the output grid.\n",
    "  - This will store the maximum values found in each window.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "    for i in range(out_h):\n",
    "        for j in range(out_w):\n",
    "```\n",
    "- **Loops over every possible position** for the top-left corner of the window:\n",
    "  - `i` goes over all rows in the output.\n",
    "  - `j` goes over all columns in the output.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "            Y[i, j] = X[i:i+h, j:j+w].max()\n",
    "```\n",
    "- **For each position**:\n",
    "  - Selects a window from `X` that starts at row `i` and column `j` and is of size `h` by `w`.\n",
    "  - Finds the maximum value in that window.\n",
    "  - Stores that maximum in the output tensor `Y` at position `[i, j]`.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "    return Y\n",
    "```\n",
    "- **Returns** the output tensor `Y` containing all the max-pooled values.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary for a Curious Kid**\n",
    "- This function slides a small box over a big grid of numbers.\n",
    "- At each spot, it looks inside the box and picks the biggest number.\n",
    "- It builds a new, smaller grid out of just those biggest numbers!\n",
    "\n",
    "Let me know if you want a step-by-step example with numbers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "39f2b33ec80d485d14046f1397484a1b",
     "grade": false,
     "grade_id": "cell-f6903ac912b48867",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 5. CNN with PyTorch\n",
    "\n",
    "Luckily, PyTorch has all kinds of convolution and pooling operations implemented for us ([link](https://pytorch.org/docs/stable/nn.html#convolution-layers)). For the previous image example, we can use [`nn.Conv2d()`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) and [`nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d).\n",
    "\n",
    "For example, the code below implements a 2D convolution layer with 3 input channels, 8 output channels, kernel shape (3, 3), stride shape (2, 2), and no padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.318269Z",
     "start_time": "2021-12-10T04:02:11.313712Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69564fc1ad54268238c4f40db99e20ce",
     "grade": false,
     "grade_id": "cell-fed411c81556bd61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "m = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=2, padding=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0be78de8dc9d5a69ce3bc67e3ed313f",
     "grade": false,
     "grade_id": "cell-a2a9c5f058a63299",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If we have an image of shape (3, 224, 224), after this convolution layer, the output shape will be (8, 111, 111). Let us verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.332495Z",
     "start_time": "2021-12-10T04:02:11.320316Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfca04cefb5bb5aed5825607e448a57b",
     "grade": false,
     "grade_id": "cell-0f405cc8b70dacfa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 111, 111])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first dimension is the batch size (1 in this case, since we only have one image)\n",
    "img = torch.randn(1, 3, 224, 224)\n",
    "m(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "How does Conv2d use input channels, output channels, and kernel size?\n",
    "What are channels?\n",
    "\n",
    "    Imagine a color image:\n",
    "        3 channels = Red, Green, Blue layers stacked together.\n",
    "    In deep learning, each “channel” is like a separate sheet of information.\n",
    "\n",
    "What does kernel_size mean?\n",
    "\n",
    "    The kernel is like a small window that slides over your image.\n",
    "    kernel_size=3 means the window is a 3×3 square (not 3, but 3 by 3).\n",
    "\n",
    "How does input and output channels work?\n",
    "\n",
    "    Input channels (3): The Conv2d layer expects images with 3 channels (like RGB).\n",
    "    Output channels (8): The Conv2d layer creates 8 new images, each one is a different “view” or pattern found by the layer.\n",
    "\n",
    "How are the kernels arranged?\n",
    "\n",
    "    For each output channel, the layer has its own set of kernels.\n",
    "    Each kernel looks at all input channels.\n",
    "    So, for every output channel, you need kernels for each input channel.\n",
    "\n",
    "The shape of the kernel tensor is:\n",
    "Code\n",
    "\n",
    "(out_channels, in_channels, kernel_height, kernel_width)\n",
    "\n",
    "For your example:\n",
    "\n",
    "    out_channels = 8\n",
    "    in_channels = 3\n",
    "    kernel_height = 3\n",
    "    kernel_width = 3\n",
    "\n",
    "So, the total kernel tensor shape is:\n",
    "Code\n",
    "\n",
    "(8, 3, 3, 3)\n",
    "\n",
    "Visual analogy:\n",
    "\n",
    "    Imagine you want to bake 8 cakes (output channels).\n",
    "    For each cake, you use 3 different flavors of batter (input channels).\n",
    "    And each flavor needs its own 3×3 mixing pattern (kernel).\n",
    "    So you have 8 cakes × 3 batters × 3×3 mixing patterns.\n",
    "\n",
    "Summary:\n",
    "\n",
    "    kernel_size means how big the window is (3×3).\n",
    "    in_channels is how many input layers.\n",
    "    out_channels is how many new output layers.\n",
    "    The kernel tensor is shaped (8, 3, 3, 3), not just 3×8.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd7e86da711a8414b9d52d54de9524e2",
     "grade": false,
     "grade_id": "cell-9219584b643b1938",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the assignment, on the other hand, we will play with sequential data. That is, each patient will be represented as a sequence of visits, and each visit will be represented as a set of diagnosis codes (a one-hot vector).\n",
    "\n",
    "Denote the number of visits for a patient as $n$, and the total number of diagnosis codes as $m$, this patient can be represented as a matrix of shape $(n, m)$. \n",
    "\n",
    "For example, let us say there are 30 diagnosis codes in total. And there is a patient with 3 visits. Then the patient can be represented as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.336663Z",
     "start_time": "2021-12-10T04:02:11.334500Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24e63a1a69f3487e34900aba06807e7c",
     "grade": false,
     "grade_id": "cell-3dad98f2297740d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# the first dimension is the batch size (1 in this case, since we only have one patient)\n",
    "# the second dimension is the total number of diagnosis codes\n",
    "# the third dimension is the total number of visits\n",
    "patient = torch.randn(1, 30, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0cb1492fd05c41ea7a8ec0df7ed7d327",
     "grade": false,
     "grade_id": "cell-6a3468c29cf4be50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can then perform 1D convolution to capture the temporal information. The code below implements an 1D convolution layer with 30 input channels, 16 output channels, kernel shape 2, stride shape 1, and no padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.341935Z",
     "start_time": "2021-12-10T04:02:11.339012Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16b678c8d73cbe2ae320c8a72a83009d",
     "grade": false,
     "grade_id": "cell-a8bf485b128c7ae2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "m = nn.Conv1d(in_channels=30, out_channels=16, kernel_size=2, stride=1, padding=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52a687236ccc963860fe4ee950a4b3ea",
     "grade": false,
     "grade_id": "cell-bdf734000abe7f27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "After convolution, we should have a tensor of shape (16, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.348702Z",
     "start_time": "2021-12-10T04:02:11.343952Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8897bda149d75b959744c27a0ad5d0e9",
     "grade": false,
     "grade_id": "cell-b28f04032643ff6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(patient).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1e9470f29a5860ca666d3db301c002be",
     "grade": false,
     "grade_id": "cell-9d53a9b48c1ce7a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Assignment [60 points]\n",
    "\n",
    "In this assignment, you will use [MIMIC-III Demo](https://physionet.org/content/mimiciii-demo/) dataset, which contains all intensive care unit (ICU) stays for 100 patients. The task is Mortality Prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21ca97a1b7e3f46655d8dcd31b538924",
     "grade": false,
     "grade_id": "cell-c23b3af3e6fcb189",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Load Data\n",
    "\n",
    "In the previous lab, we have preprocessed the data. Thus, for this lab, we will directly use the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.479581Z",
     "start_time": "2021-12-10T04:02:11.350484Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbaaa5edc711916599624a613f06a4e0",
     "grade": false,
     "grade_id": "cell-f0553747aa0e13aa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd0a1c525133be2ae4004438740d093f",
     "grade": false,
     "grade_id": "cell-3b6568c0ace0ba15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here are the helper fuctions and CustomDataset from the previous lab. \n",
    "\n",
    "The only difference is that, starting from this lab, we will use the entire patient visit instead of only the last visit. Due to this reason, we will only keep patients with more than one visits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.486540Z",
     "start_time": "2021-12-10T04:02:11.481725Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53906d0f1c84a92784bcc4b67f235b15",
     "grade": false,
     "grade_id": "cell-658c7e525174d846",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# two helper functions\n",
    "\n",
    "TOTAL_NUM_CODES = 271\n",
    "\n",
    "\n",
    "def read_csv(filename):\n",
    "    \"\"\" reading csv from filename \"\"\"\n",
    "    data = []\n",
    "    with open(filename, \"r\") as file:\n",
    "        csv_reader = csv.DictReader(file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "    header = list(data[0].keys())\n",
    "    return header, data\n",
    "\n",
    "\n",
    "def to_one_hot(label, num_class):\n",
    "    \"\"\" convert to one hot label \"\"\"\n",
    "    one_hot_label = [0] * num_class\n",
    "    for i in label:\n",
    "        one_hot_label[i] = 1\n",
    "    return one_hot_label"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This code defines two helper functions. The first, read_csv, is used to read a CSV file and return both the header (column names) and the data (as a list of dictionaries, one for each row). It relies on Python’s built-in csv module to parse the file. The second function, to_one_hot, takes a list of integer labels and the total number of classes, and returns a one-hot encoded list—a list of zeros except for ones at the indices corresponding to the labels provided. This is commonly used in machine learning when you need to represent categorical data in a numerical format suitable for algorithms.\n",
    "\n",
    "Copilot said: Let’s break down this part of the\n",
    "\n",
    "Let’s break down this part of the function in detail:\n",
    "Python\n",
    "\n",
    "for i in label:\n",
    "    one_hot_label[i] = 1\n",
    "return one_hot_label\n",
    "\n",
    "What’s Happening Here?\n",
    "1. for i in label:\n",
    "\n",
    "    This line starts a loop.\n",
    "    It goes through each value i in the label variable.\n",
    "    label is expected to be a list (or any iterable) of integers.\n",
    "        Each integer represents a class index.\n",
    "\n",
    "2. one_hot_label[i] = 1\n",
    "\n",
    "    one_hot_label is a list of zeros, created earlier in the function.\n",
    "    For each index i in the label list, this line sets the value at position i in one_hot_label to 1.\n",
    "    This means: if label = [2, 4] and num_class = 6, then:\n",
    "        Start: [0, 0, 0, 0, 0, 0]\n",
    "        Set index 2 to 1: [0, 0, 1, 0, 0, 0]\n",
    "        Set index 4 to 1: [0, 0, 1, 0, 1, 0]\n",
    "\n",
    "3. return one_hot_label\n",
    "\n",
    "    After the loop, it returns the modified one_hot_label list.\n",
    "    This list is a one-hot encoded vector, where indices listed in label are 1, and the rest are 0.\n",
    "\n",
    "Simple Example\n",
    "\n",
    "Suppose you have:\n",
    "\n",
    "    label = [1, 3]\n",
    "    num_class = 5\n",
    "\n",
    "Process:\n",
    "\n",
    "    one_hot_label = [0, 0, 0, 0, 0] (5 zeros)\n",
    "    Loop:\n",
    "        i = 1 → set position 1 to 1: [0, 1, 0, 0, 0]\n",
    "        i = 3 → set position 3 to 1: [0, 1, 0, 1, 0]\n",
    "    Return [0, 1, 0, 1, 0]\n",
    "\n",
    "\n",
    "In summary, these helpers are designed for data preprocessing: one for loading CSV-formatted data, and the other for transforming categorical labels into a machine-friendly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.497251Z",
     "start_time": "2021-12-10T04:02:11.488743Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0833752e0e9041149f1a7faa6320991e",
     "grade": false,
     "grade_id": "cell-4c4eda236985b3ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # read the csv\n",
    "        self._df = pd.read_csv(f'{DATA_PATH}/data.csv')\n",
    "        # split diagnosis code index by ';' and convert it to integer\n",
    "        self._df.icd9 = self._df.icd9.apply(lambda x: [int(i) for i in x.split(';')])\n",
    "        # build data dict\n",
    "        self._build_data_dict()\n",
    "        # a list of subject ids\n",
    "        self._subj_ids = list(self._data.keys())\n",
    "        # sort the subject ids to maintain a fixed order\n",
    "        self._subj_ids.sort()\n",
    "    \n",
    "    def _build_data_dict(self):\n",
    "        \"\"\" \n",
    "        build SUBJECT_ID to ADMISSION dict\n",
    "            - subject_id\n",
    "                - icd9: a list of ICD9 code index\n",
    "                - mortality: 0/1 morality label\n",
    "        \"\"\"\n",
    "        dict_data = {}\n",
    "        df = self._df.groupby('subject_id').agg({'mortality': lambda x: x.iloc[0], 'icd9': list}).reset_index()\n",
    "        for idx, row in df.iterrows():\n",
    "            subj_id = row.subject_id\n",
    "            # only keep patients with more than 1 visit\n",
    "            if len(row.icd9) >= 2:\n",
    "                dict_data[subj_id] = {}\n",
    "                dict_data[subj_id]['icd9'] = row.icd9\n",
    "                dict_data[subj_id]['mortality'] = row.mortality\n",
    "        self._data = dict_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\" return the number of samples (i.e. patients). \"\"\"\n",
    "        return len(self._subj_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" generates one sample of data. \"\"\"\n",
    "        # obtain the subject id\n",
    "        subj_id = self._subj_ids[index]\n",
    "        # obtain the data dict by subject id\n",
    "        data = self._data[subj_id]\n",
    "        # convert last admission's diagnosis code index to one hot\n",
    "        x = torch.tensor([to_one_hot(visit, TOTAL_NUM_CODES) for visit in data['icd9']], dtype=torch.float32)\n",
    "        # mortality label\n",
    "        y = torch.tensor(data['mortality'], dtype=torch.float32)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absolutely! Let’s create a simple example to show how your `CustomDataset` class works step by step.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Sample CSV Data\n",
    "\n",
    "Suppose your CSV (`data.csv`) looks like this:\n",
    "\n",
    "| subject_id | icd9        | mortality |\n",
    "|------------|-------------|-----------|\n",
    "| 1001       | 12;45;100   | 0         |\n",
    "| 1001       | 33;56       | 0         |\n",
    "| 1002       | 5;99        | 1         |\n",
    "| 1002       | 7           | 1         |\n",
    "| 1003       | 5           | 0         |  ← Only one visit, will be ignored\n",
    "\n",
    "---\n",
    "\n",
    "## 2. What Happens Step By Step\n",
    "\n",
    "### **a. Read and Process Data**\n",
    "- Only patients with 2 or more visits are kept: 1001 and 1002.\n",
    "\n",
    "### **b. After Processing**\n",
    "\n",
    "- For **1001**:\n",
    "  - icd9: `[[12,45,100], [33,56]]`\n",
    "  - mortality: `0`\n",
    "- For **1002**:\n",
    "  - icd9: `[[5,99], [7]]`\n",
    "  - mortality: `1`\n",
    "\n",
    "### **c. One-Hot Encoding (Assume `TOTAL_NUM_CODES = 101` for simplicity)**\n",
    "\n",
    "- The `to_one_hot` function will create a 101-length array of 0s, with 1s at the indices of the codes.\n",
    "\n",
    "#### For 1001’s first admission `[12,45,100]`:\n",
    "```\n",
    "[0, 0, ..., 1 at 12, ..., 1 at 45, ..., 1 at 100]\n",
    "```\n",
    "#### For 1001’s second admission `[33,56]`:\n",
    "```\n",
    "[0, 0, ..., 1 at 33, ..., 1 at 56, ..., 0]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. What Does `__getitem__` Return?\n",
    "\n",
    "### For patient at index 0 (subject_id 1001):\n",
    "\n",
    "- `x` will be a tensor of shape `(2, 101)`:\n",
    "  - First row: one-hot for `[12,45,100]`\n",
    "  - Second row: one-hot for `[33,56]`\n",
    "- `y` will be a tensor: `0.0` (float)\n",
    "\n",
    "### For patient at index 1 (subject_id 1002):\n",
    "\n",
    "- `x`: tensor of shape `(2, 101)`:\n",
    "  - First row: one-hot for `[5,99]`\n",
    "  - Second row: one-hot for `[7]`\n",
    "- `y`: tensor: `1.0` (float)\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Example in Code\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "TOTAL_NUM_CODES = 101\n",
    "\n",
    "def to_one_hot(label, num_class):\n",
    "    one_hot_label = [0] * num_class\n",
    "    for i in label:\n",
    "        one_hot_label[i] = 1\n",
    "    return one_hot_label\n",
    "\n",
    "# Example for 1001\n",
    "visits = [[12, 45, 100], [33, 56]]\n",
    "x = torch.tensor([to_one_hot(visit, TOTAL_NUM_CODES) for visit in visits], dtype=torch.float32)\n",
    "y = torch.tensor(0.0, dtype=torch.float32)\n",
    "print(\"x shape:\", x.shape)  # (2, 101)\n",
    "print(\"First admission one-hot (indices 12,45,100):\", x[0].nonzero(as_tuple=True)[0].tolist())\n",
    "print(\"Second admission one-hot (indices 33,56):\", x[1].nonzero(as_tuple=True)[0].tolist())\n",
    "print(\"y:\", y)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "x shape: torch.Size([2, 101])\n",
    "First admission one-hot (indices 12,45,100): [12, 45, 100]\n",
    "Second admission one-hot (indices 33,56): [33, 56]\n",
    "y: tensor(0.)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Summary**\n",
    "\n",
    "- Each patient is represented as a sequence of admissions.\n",
    "- Each admission is a one-hot vector marking which diagnoses they had.\n",
    "- The label is their mortality (0 or 1).\n",
    "- When you get a patient from the dataset, you get their admissions (as a tensor of one-hot vectors) and their mortality label.\n",
    "\n",
    "Let me know if you want to see this as a runnable script or with more/different data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.525774Z",
     "start_time": "2021-12-10T04:02:11.499034Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d98adb3cc8b250351e00560fb80dad7",
     "grade": false,
     "grade_id": "cell-64bd9fd8d521c2da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset: 14\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset()\n",
    "print('Size of dataset:', len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copilot said: Great question! Let’s break down why `CustomDataset()`\n",
    "\n",
    "Great question! Let’s break down why CustomDataset() works and prints Size of dataset: 14 even though you didn’t pass any data directly as an argument.\n",
    "1. Where Does the Data Come From?\n",
    "\n",
    "Look at the CustomDataset class’s __init__ method:\n",
    "Python\n",
    "\n",
    "def __init__(self):\n",
    "    # read the csv\n",
    "    self._df = pd.read_csv(f'{DATA_PATH}/data.csv')\n",
    "    ...\n",
    "\n",
    "Key point:\n",
    "\n",
    "    The data is loaded from a CSV file on disk: f'{DATA_PATH}/data.csv'.\n",
    "    DATA_PATH is a variable that must be defined somewhere in your code or notebook (often at the top).\n",
    "    pd.read_csv(...) reads the CSV file and loads the data into a pandas DataFrame (self._df).\n",
    "\n",
    "2. How Does the Class Know What Data to Use?\n",
    "\n",
    "    The class is hardcoded to look for the file at a specific location (DATA_PATH/data.csv).\n",
    "    You don’t need to pass the data as an argument because the class is designed to always load its data from that file.\n",
    "    This is a design choice: the data source (file location) is fixed inside the class, not passed as a parameter.\n",
    "\n",
    "3. Why Does len(dataset) Return 14?\n",
    "\n",
    "    After reading the CSV, the class processes and filters the data (for example, filtering only patients with more than 1 visit).\n",
    "    The list of valid patients (subject IDs) is stored in self._subj_ids.\n",
    "    __len__ returns the length of this list.\n",
    "    In your case, after filtering, there are 14 valid patients in the CSV file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.531747Z",
     "start_time": "2021-12-10T04:02:11.527176Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d774d9394a9ad87f2df6a6006cb7b65",
     "grade": false,
     "grade_id": "cell-5c1cb6c063c46208",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset: 9\n",
      "Length of test dataset: 5\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "\n",
    "split = int(len(dataset)*0.7)\n",
    "\n",
    "lengths = [split, len(dataset) - split]\n",
    "train_dataset, test_dataset = random_split(dataset, lengths)\n",
    "\n",
    "print(\"Length of train dataset:\", len(train_dataset))\n",
    "print(\"Length of test dataset:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the split indices for 70% train, 30% test\n",
    "split = int(len(dataset) * 0.7)  # 0.7 * 14 = 9.8 → 9 after int()\n",
    "lengths = [split, len(dataset) - split]  # [9, 5]\n",
    "\n",
    "# Randomly split the dataset\n",
    "train_dataset, test_dataset = random_split(dataset, lengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "267f1a0762e9b450a87f3e22c3755942",
     "grade": false,
     "grade_id": "cell-b488ab9781c9b968",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here is an example of $x$, and $y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.541545Z",
     "start_time": "2021-12-10T04:02:11.533133Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e326c8f4e425c160a0a99fb3e9e8966",
     "grade": false,
     "grade_id": "cell-062f87c8a470e916",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example x (shape torch.Size([2, 271])):\n",
      " tensor([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "         0.]])\n",
      "Example y:\n",
      " tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x, y = train_dataset[0]\n",
    "print(f'Example x (shape {x.shape}):\\n', x)\n",
    "print(f'Example y:\\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fbcfa7916cff14d12c59b0b25e62292",
     "grade": false,
     "grade_id": "cell-2de64c220bed55ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can see that $x$ is of shape $(2, 271)$, which means there are $271$ diagnosis codes in total, and this patient has two visits. It is in one-hot format. A $1$ in position $i$ means that diagnosis code of index $i$ appears in the that visit.\n",
    "\n",
    "And $y$ is either $0$ or $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c7b530cad4b7bf74f6f77af96f1e37a",
     "grade": false,
     "grade_id": "cell-0de19a4515ddf35b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Padding [20 points]\n",
    "\n",
    "Note that the first dimension of $x$ can be different for different patients (i.e., different patients will have different number of visits). Thus we need to implement a padding function (similar to the zero padding in images).\n",
    "\n",
    "To achieve this goal, we will implement a special collage function. This collate function `collate_fn()` will be called by `DataLoader` after fetching a list of samples using the indices from `CustomDataset` to collate the list of samples into batches.\n",
    "\n",
    "For example, assume the `DataLoader` gets a list of two samples (here, assume the total number of codes is 3). \n",
    "\n",
    "```\n",
    "[ [ [0, 1, 0], [1, 0, 1] ], \n",
    "  [ [0, 0, 1], [0, 1, 1], [0, 1, 1] ] ]\n",
    "```\n",
    "\n",
    "where the first patient has two visits `[0, 1, 0]` and `[1, 0, 1]` and the second patient has three visits `[0, 0, 1]`, `[0, 1, 1]`, and `[0, 1, 1]`.\n",
    "\n",
    "The collate function `collate_fn()` is supposed to pad them into the same shape (2, 3), where 2 is the number of patients, and 3 is the maximum number of visits.\n",
    "\n",
    "```\n",
    "[ [ [0, 1, 0], [1, 0, 1], *[0, 0, 0]* ], \n",
    "  [ [0, 0, 1], [0, 1, 1],  [0, 1, 1] ] ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplified explanation\n",
    "Here’s a simplified version of your text:\n",
    "\n",
    "Different patients can have different numbers of visits, so their data arrays have varying first dimensions. To batch this data, we need to pad shorter patient records (with zeros, like zero-padding in images) so that all patients in a batch have the same number of visits.\n",
    "\n",
    "We use a custom collate function, collate_fn(), in the DataLoader to do this padding automatically. For example, if one patient has 2 visits and another has 3, we pad the first patient’s data to have 3 visits (adding a row of zeros):\n",
    "\n",
    "Original samples:\n",
    "[\n",
    "  [[0, 1, 0], [1, 0, 1]],                 # 2 visits\n",
    "  [[0, 0, 1], [0, 1, 1], [0, 1, 1]]       # 3 visits\n",
    "]\n",
    "\n",
    "After padding:\n",
    "[\n",
    "  [[0, 1, 0], [1, 0, 1], [0, 0, 0]],     # now 3 visits (last one is padding)\n",
    "  [[0, 0, 1], [0, 1, 1], [0, 1, 1]]      # unchanged\n",
    "]\n",
    "\n",
    "This way, all patient data in a batch has the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.548482Z",
     "start_time": "2021-12-10T04:02:11.543228Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    TODO: Collate the the list of samples into batches. For each patient, you need to pad the diagnosis\n",
    "        sequences to the sample shape (max # visits, total # diagnosis codes).\n",
    "    \n",
    "    Arguments:\n",
    "        data: a list of samples fetched from `CustomDataset`\n",
    "        \n",
    "    Outputs:\n",
    "        x: a tensor of shape (# patients, total # diagnosis codes, max # visits) of type torch.float\n",
    "        y: a tensor of shape (# patients) of type torch.float\n",
    "        \n",
    "    Note that you can obtains the list of diagnosis codes and the list of mortality labels\n",
    "        using: `sequences, labels = zip(*data)`\n",
    "    \"\"\"\n",
    "\n",
    "    sequences, labels = zip(*data)\n",
    "\n",
    "    y = torch.tensor(labels, dtype=torch.float)\n",
    "    \n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [patient.shape[0] for patient in sequences]\n",
    "    total_num_codes = sequences[0].shape[1]\n",
    "\n",
    "    max_num_visits = max(num_visits)\n",
    "    \n",
    "    x = torch.zeros((num_patients, total_num_codes, max_num_visits), dtype=torch.float)\n",
    "\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            x[i_patient, :, j_visit] = visit.float()\n",
    "            # your code here\n",
    "            #raise NotImplementedError\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplified example\n",
    "Suppose you have two patients, and each patient has a different number of visits. For each visit, you have a 3-code diagnosis vector.\n",
    "Python\n",
    "\n",
    "import torch\n",
    "\n",
    "# Patient 1: 2 visits, each with 3 codes\n",
    "patient1 = torch.tensor([\n",
    "    [1, 0, 0],  # visit 1\n",
    "    [0, 1, 1]   # visit 2\n",
    "])\n",
    "\n",
    "# Patient 2: 3 visits, each with 3 codes\n",
    "patient2 = torch.tensor([\n",
    "    [0, 1, 0],  # visit 1\n",
    "    [1, 0, 1],  # visit 2\n",
    "    [0, 0, 1]   # visit 3\n",
    "])\n",
    "\n",
    "# Labels (e.g. mortality, just for demonstration)\n",
    "label1 = 0\n",
    "label2 = 1\n",
    "\n",
    "# Combine into data list as (sequence, label) pairs\n",
    "data = [\n",
    "    (patient1, label1),\n",
    "    (patient2, label2)\n",
    "]\n",
    "\n",
    "What collate_fn Does\n",
    "\n",
    "    Finds the max number of visits (here: 3, since patient2 has 3 visits)\n",
    "    Pads patient1’s visits to 3 (adds a row of zeros)\n",
    "    Organizes the data into a tensor of shape (number of patients, number of codes, max visits)\n",
    "\n",
    "Step-by-Step Output\n",
    "\n",
    "Let’s show this in code by filling in the missing part of your function and running it:\n",
    "Python\n",
    "\n",
    "def collate_fn(data):\n",
    "    sequences, labels = zip(*data)\n",
    "    y = torch.tensor(labels, dtype=torch.float)\n",
    "    num_patients = len(sequences)\n",
    "    num_visits = [patient.shape[0] for patient in sequences]\n",
    "    total_num_codes = sequences[0].shape[1]\n",
    "    max_num_visits = max(num_visits)\n",
    "    x = torch.zeros((num_patients, total_num_codes, max_num_visits), dtype=torch.float)\n",
    "    for i_patient, patient in enumerate(sequences):\n",
    "        for j_visit, visit in enumerate(patient):\n",
    "            x[i_patient, :, j_visit] = visit.float()\n",
    "    return x, y\n",
    "\n",
    "x, y = collate_fn(data)\n",
    "\n",
    "print(\"x (batched visits):\")\n",
    "print(x)\n",
    "print(\"x shape:\", x.shape)\n",
    "print(\"y (labels):\", y)\n",
    "\n",
    "Output\n",
    "Code\n",
    "\n",
    "x (batched visits):\n",
    "tensor([[[1., 0., 0.],\n",
    "         [0., 1., 0.],\n",
    "         [0., 1., 0.]],\n",
    "        [[0., 1., 0.],\n",
    "         [1., 0., 0.],\n",
    "         [0., 1., 1.]]])\n",
    "x shape: torch.Size([2, 3, 3])\n",
    "y (labels): tensor([0., 1.])\n",
    "\n",
    "Explanation:\n",
    "\n",
    "    Each patient’s data is padded so they both have 3 visits.\n",
    "    For patient 1, the third visit is all zeros (padding).\n",
    "    The result is ready for batch processing in deep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.560530Z",
     "start_time": "2021-12-10T04:02:11.550634Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fd34743e502b3822ca541e53db290494",
     "grade": true,
     "grade_id": "cell-3e2ee044e3a07c8a",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "loader = DataLoader(train_dataset, batch_size=4, collate_fn=collate_fn)\n",
    "loader_iter = iter(loader)\n",
    "x, y = next(loader_iter)\n",
    "\n",
    "assert x.dtype == torch.float\n",
    "assert y.dtype == torch.float\n",
    "\n",
    "assert x.shape[:-1] == (4, 271)\n",
    "assert y.shape == (4,)\n",
    "\n",
    "for i in range(4):\n",
    "    real_x, real_y = train_dataset[i]\n",
    "    for j in range(real_x.shape[0]):\n",
    "        visit = real_x[j]\n",
    "        got = x[i, :, j]\n",
    "        assert all(visit == got)\n",
    "        assert real_y == y[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5de130a1f1595f984088438d01552a31",
     "grade": false,
     "grade_id": "cell-54947dd443e4ee61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We need to pad the sequences into the same length so that we can do batch training on GPU, which will run much faster. Or, if they have different length, we have to process them one by one. This is extremely slow, especially with a large dataset.\n",
    "\n",
    "You may also wonder will this padding add some extra noise to the dataset (because we change the number of visits for some patients). The answer is: it depends. Sometimes, padding will bring in some noise and we need to have a separate mask to remove the noise later (you will see this in the next lab).\n",
    "\n",
    "But in this lab, it does not matter. Because zero padding will not affect the convolution operation. Zero times zero is still zero (assume we do not have bias parameter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code sets up PyTorch data loaders to efficiently provide batches of data from your training and test datasets. The custom collate_fn function is used to pad and arrange each batch. Shuffling is enabled for training data to improve learning. Finally, the code prints out the number of batches for both training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4ed4b1dab48408a4211e3af5b5f68daa",
     "grade": false,
     "grade_id": "cell-53f4b956f04397be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Data Loader\n",
    "\n",
    "Now, we can load the dataset into the data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.566002Z",
     "start_time": "2021-12-10T04:02:11.562153Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f3827264d8672c03cda07127dbd909a",
     "grade": false,
     "grade_id": "cell-c1a050941d5fba0d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train batches: 3\n",
      "# of test batches: 2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# how many samples per batch to load\n",
    "batch_size = 4\n",
    "\n",
    "# prepare dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "print(\"# of train batches:\", len(train_loader))\n",
    "print(\"# of test batches:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.573086Z",
     "start_time": "2021-12-10T04:02:11.567902Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7dccaef5026443cacf5ea0916ddff3df",
     "grade": false,
     "grade_id": "cell-cf668e469e5f3383",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a batch x: torch.Size([4, 271, 3])\n",
      "Shape of a batch y: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "x, y = next(train_iter)\n",
    "\n",
    "print('Shape of a batch x:', x.shape)\n",
    "print('Shape of a batch y:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copilot said: Let’s break down what these shapes mean: ###\n",
    "\n",
    "Let’s break down what these shapes mean:\n",
    "x: torch.Size([4, 271, 3])\n",
    "\n",
    "    x is your batch of input data (for example, visit sequences for patients).\n",
    "    4: The batch contains 4 samples (e.g., 4 patients).\n",
    "    271: Each visit is represented by a vector of 271 diagnosis codes (so you have 271 features per visit).\n",
    "    3: Each patient (in this batch) has data for up to 3 visits (padded if needed).\n",
    "\n",
    "So:\n",
    "x is a 3-dimensional tensor with shape:\n",
    "[number of patients in batch, number of codes per visit, number of visits]\n",
    "Or:\n",
    "[batch, codes, visits]\n",
    "Example: 4 patients, 271 codes, 3 visits each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6aa71441902394ddf601dbe3f4a984ee",
     "grade": false,
     "grade_id": "cell-67bd2a4540e34723",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Build the Model [20 points]\n",
    "\n",
    "Now, let us build a 1D CNN model. For each patient, the CNN model will take an input tensor of shape (# of visits, total # of codes), and produce an output tensor of 1-dim (0 for non-mortality, 1 for moratality). The detailed model architecture is shown in the table below.\n",
    "\n",
    "Layers | Configuration | Activation Function\n",
    "--- | --- | ---\n",
    "convolution | in channels 271, out channels 32, kernel size 2, stride 1, padding 0, bias False | -\n",
    "dropout | probability 0.5 | - \n",
    "fully connected | input size 32, output size 1 | Sigmoid\n",
    "\n",
    "Note that you have to set `bias=Flase` for the convolution layer. Only in this way can we ignore the noise introduced by padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔 Why 1D CNN?\n",
    "\n",
    "Because your data is sequential in one direction — over time (visits).\n",
    "🔍 Your input:\n",
    "\n",
    "Each patient’s input is shaped like:\n",
    "\n",
    "(number of visits, number of medical codes)\n",
    "→ for example: (10, 271)\n",
    "\n",
    "That means:\n",
    "\n",
    "    Each row is a visit (a point in time),\n",
    "\n",
    "    Each column is a medical code (features at that visit).\n",
    "\n",
    "So the input is like a sequence of visit-vectors — similar to a time series.\n",
    "✅ Why 1D is appropriate:\n",
    "\n",
    "    1D CNN looks for patterns along the sequence of visits, using a sliding window (the kernel).\n",
    "\n",
    "    It treats each visit as a \"time step\" and learns local temporal patterns (e.g., how a disease progresses across visits).\n",
    "\n",
    "    2D CNN would be for images (2D spatial data), not appropriate here.\n",
    "\n",
    "🧠 Analogy:\n",
    "\n",
    "Think of it like this:\n",
    "\n",
    "    1D CNN is to time series or sequential visit data what\n",
    "\n",
    "    2D CNN is to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.579501Z",
     "start_time": "2021-12-10T04:02:11.574694Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Build the CNN shown above.\n",
    "HINT: Consider using `nn.Conv1d`, `nn.MaxPool1d`, `nn.Dropout`, `nn.Linear`, `torch.sigmoid`.\n",
    "\"\"\"\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # DO NOT change the names\n",
    "        self.conv = nn.Conv1d(in_channels=271, out_channels=32, kernel_size=2, stride=1, padding=0, bias=False)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc = nn.Linear(32, 1)\n",
    "        \n",
    "        \n",
    "        # your code here\n",
    "        #raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        TODO: 1. pass x through the convolution layer\n",
    "              2. pass x through the dropout layer\n",
    "              3. sum x by the last dimension (i.e., visits)\n",
    "              4. pass x through the linear and sigmoid layer\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "         \n",
    "        x = self.conv(x)       # → [batch, 32, new_seq_len]\n",
    "        x = self.dropout(x)\n",
    "        x = x.sum(dim=2)       # sum across time (visits)\n",
    "        x = self.fc(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "            \n",
    "        #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.584104Z",
     "start_time": "2021-12-10T04:02:11.581207Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49828d6df5f2f89844c30010c2772edc",
     "grade": false,
     "grade_id": "cell-4f9ada7c74c60887",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv): Conv1d(271, 32, kernel_size=(2,), stride=(1,), bias=False)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize the CNN\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.600029Z",
     "start_time": "2021-12-10T04:02:11.591707Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5223999b8c57440851e2b24380def88f",
     "grade": true,
     "grade_id": "cell-4ee174f9a07b657c",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "model = Net()\n",
    "\n",
    "assert model.conv.in_channels == 271\n",
    "assert model.conv.out_channels == 32\n",
    "assert model.conv.kernel_size == (2,)\n",
    "assert model.conv.stride == (1,)\n",
    "assert model.conv.padding == (0,)\n",
    "assert model.conv.bias is None\n",
    "assert model.fc.in_features == 32\n",
    "assert model.fc.out_features == 1\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "x, y = next(train_iter)\n",
    "output = model.forward(x)\n",
    "assert output.shape == (4, 1), \"Net() is wrong!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b57e302ec6503ce207a8f013692a7a6",
     "grade": false,
     "grade_id": "cell-4664f9a698dfb0ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have a network, let's see what happens when we pass in some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.608486Z",
     "start_time": "2021-12-10T04:02:11.601798Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "707e076b2b7a17603b9d198784ace7e3",
     "grade": false,
     "grade_id": "cell-fa0dcdf281213277",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([4, 271, 3])\n",
      "Output shape:  torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "\n",
    "# Grab some data \n",
    "train_iter = iter(train_loader)\n",
    "x, y = next(train_iter)\n",
    "\n",
    "# Forward pass through the network\n",
    "output = model.forward(x)\n",
    "\n",
    "print('Input x shape:', x.shape)\n",
    "print('Output shape: ', output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57669650616a8e8eddbf6abe743eafaf",
     "grade": false,
     "grade_id": "cell-af2e55271ae666f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Train the Network [20 points]\n",
    "\n",
    "In this step, you will train the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.613266Z",
     "start_time": "2021-12-10T04:02:11.610464Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Define the loss (BCELoss), assign it to `criterion`.\n",
    "\n",
    "REFERENCE: https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss\n",
    "\"\"\"\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# your code here\n",
    "#raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.618100Z",
     "start_time": "2021-12-10T04:02:11.614953Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: Define the optimizer (SGD) with learning rate 0.01, assign it to `optimizer`.\n",
    "\n",
    "REFERENCE: https://pytorch.org/docs/stable/optim.html\n",
    "\"\"\"\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# your code here\n",
    "#raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:11.624041Z",
     "start_time": "2021-12-10T04:02:11.620498Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4509c2beeedfe018a3c100fbb8f6213e",
     "grade": true,
     "grade_id": "cell-19ffe4a84d047d3a",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "AUTOGRADER CELL. DO NOT MODIFY THIS.\n",
    "'''\n",
    "\n",
    "assert type(criterion) is nn.modules.loss.BCELoss, \"criterion is not BCELoss!\"\n",
    "assert type(optimizer) is torch.optim.SGD, \"optimizer is not SGD!\"\n",
    "assert optimizer.param_groups[0]['lr'] == 0.01, \"learning rate is not 0.01!\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be1d0b7e0ebd3324f7feadda4f36e937",
     "grade": false,
     "grade_id": "cell-c5125efa9aa9e316",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can train the model. The following two cell are exactly the same as previous lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:12.018609Z",
     "start_time": "2021-12-10T04:02:11.626150Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8293b6ab0aee29b614665d63e53c852",
     "grade": false,
     "grade_id": "cell-acf118b9d1359c94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "#input: Y_score,Y_pred,Y_true\n",
    "#output: accuracy, auc, precision, recall, f1-score\n",
    "def classification_metrics(Y_score, Y_pred, Y_true):\n",
    "    acc, auc, precision, recall, f1score = accuracy_score(Y_true, Y_pred), \\\n",
    "                                           roc_auc_score(Y_true, Y_score), \\\n",
    "                                           precision_score(Y_true, Y_pred), \\\n",
    "                                           recall_score(Y_true, Y_pred), \\\n",
    "                                           f1_score(Y_true, Y_pred)\n",
    "    return acc, auc, precision, recall, f1score\n",
    "\n",
    "\n",
    "#input: model, loader\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_y_true = torch.LongTensor()\n",
    "    all_y_pred = torch.LongTensor()\n",
    "    all_y_score = torch.FloatTensor()\n",
    "    for x, y in loader:\n",
    "        # pass the input through the model\n",
    "        y_hat = model(x)\n",
    "        # convert shape from [batch size, 1] to [batch size]\n",
    "        y_hat = y_hat.view(y_hat.shape[0])\n",
    "        y_pred = (y_hat > 0.5).type(torch.float)\n",
    "        all_y_true = torch.cat((all_y_true, y.to('cpu')), dim=0)\n",
    "        all_y_pred = torch.cat((all_y_pred,  y_pred.to('cpu')), dim=0)\n",
    "        all_y_score = torch.cat((all_y_score,  y_hat.to('cpu')), dim=0)\n",
    "        \n",
    "    acc, auc, precision, recall, f1 = classification_metrics(all_y_score.detach().numpy(), \n",
    "                                                             all_y_pred.detach().numpy(), \n",
    "                                                             all_y_true.detach().numpy())\n",
    "    print(f\"acc: {acc:.3f}, auc: {auc:.3f}, precision: {precision:.3f}, recall: {recall:.3f}, f1: {f1:.3f}\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🖼️ Example:\n",
    "\n",
    "Let’s say you have two batches.\n",
    "\n",
    "Batch 1:\n",
    "\n",
    "    y = [1, 0]\n",
    "\n",
    "    y_pred = [1, 0]\n",
    "\n",
    "    y_hat = [0.9, 0.2]\n",
    "\n",
    "Batch 2:\n",
    "\n",
    "    y = [0, 1]\n",
    "\n",
    "    y_pred = [0, 1]\n",
    "\n",
    "    y_hat = [0.3, 0.8]\n",
    "\n",
    "After cat, you get:\n",
    "\n",
    "all_y_true = [1, 0, 0, 1]\n",
    "all_y_pred = [1, 0, 0, 1]\n",
    "all_y_score = [0.9, 0.2, 0.3, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:12.036509Z",
     "start_time": "2021-12-10T04:02:12.020462Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "993ab964d2f0eb1f1d4827536d11b9a1",
     "grade": false,
     "grade_id": "cell-febc6644c84df57d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model perfomance before training:\n",
      "acc: 0.667, auc: 0.571, precision: 0.750, recall: 0.857, f1: 0.800\n",
      "acc: 0.800, auc: 0.500, precision: 0.750, recall: 1.000, f1: 0.857\n"
     ]
    }
   ],
   "source": [
    "print(\"model perfomance before training:\")\n",
    "evaluate(model, train_loader)\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🏋️‍♂️ High-Level Summary\n",
    "\n",
    "    Train for n_epochs (e.g. 10 times over the training dataset).\n",
    "\n",
    "    For each mini-batch of data:\n",
    "\n",
    "        Do a forward pass.\n",
    "\n",
    "        Calculate the loss.\n",
    "\n",
    "        Do a backward pass to compute gradients.\n",
    "\n",
    "        Update model weights using the optimizer (SGD).\n",
    "\n",
    "    After each epoch, print the loss and evaluate on both train & test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T04:02:12.209871Z",
     "start_time": "2021-12-10T04:02:12.038136Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f42f50db9718d22b025ef97b8b15b86",
     "grade": false,
     "grade_id": "cell-9e7554a3ce8fc984",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.655572\n",
      "acc: 0.778, auc: 0.571, precision: 0.778, recall: 1.000, f1: 0.875\n",
      "acc: 0.800, auc: 0.500, precision: 0.750, recall: 1.000, f1: 0.857\n",
      "Epoch: 2 \tTraining Loss: 0.642107\n",
      "acc: 0.778, auc: 0.643, precision: 0.778, recall: 1.000, f1: 0.875\n",
      "acc: 0.800, auc: 0.500, precision: 0.750, recall: 1.000, f1: 0.857\n",
      "Epoch: 3 \tTraining Loss: 0.620835\n",
      "acc: 0.778, auc: 0.857, precision: 0.778, recall: 1.000, f1: 0.875\n",
      "acc: 0.800, auc: 0.500, precision: 0.750, recall: 1.000, f1: 0.857\n",
      "Epoch: 4 \tTraining Loss: 0.664610\n",
      "acc: 0.778, auc: 0.929, precision: 0.778, recall: 1.000, f1: 0.875\n",
      "acc: 0.800, auc: 0.500, precision: 0.750, recall: 1.000, f1: 0.857\n",
      "Epoch: 5 \tTraining Loss: 0.593949\n",
      "acc: 0.778, auc: 0.929, precision: 0.778, recall: 1.000, f1: 0.875\n",
      "acc: 0.800, auc: 0.500, precision: 0.750, recall: 1.000, f1: 0.857\n",
      "Epoch: 6 \tTraining Loss: 0.575149\n",
      "acc: 0.778, auc: 1.000, precision: 0.778, recall: 1.000, f1: 0.875\n",
      "acc: 0.600, auc: 0.167, precision: 0.600, recall: 1.000, f1: 0.750\n",
      "Epoch: 7 \tTraining Loss: 0.619426\n",
      "acc: 0.889, auc: 1.000, precision: 0.875, recall: 1.000, f1: 0.933\n",
      "acc: 0.800, auc: 0.500, precision: 0.750, recall: 1.000, f1: 0.857\n",
      "Epoch: 8 \tTraining Loss: 0.580927\n",
      "acc: 0.889, auc: 1.000, precision: 0.875, recall: 1.000, f1: 0.933\n",
      "acc: 0.600, auc: 0.500, precision: 0.600, recall: 1.000, f1: 0.750\n",
      "Epoch: 9 \tTraining Loss: 0.542189\n",
      "acc: 0.889, auc: 1.000, precision: 0.875, recall: 1.000, f1: 0.933\n",
      "acc: 0.600, auc: 0.333, precision: 0.600, recall: 1.000, f1: 0.750\n",
      "Epoch: 10 \tTraining Loss: 0.606264\n",
      "acc: 0.889, auc: 1.000, precision: 0.875, recall: 1.000, f1: 0.933\n",
      "acc: 0.600, auc: 0.333, precision: 0.600, recall: 1.000, f1: 0.750\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "# feel free to change this\n",
    "n_epochs = 10\n",
    "\n",
    "# prep model for training\n",
    "model.train()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    train_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        \"\"\" Step 1. clear gradients \"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        \"\"\"  Step 2. perform forward pass using `model`, save the output to y_hat \"\"\"\n",
    "        y_hat = model(x)\n",
    "        \"\"\" Step 3. calculate the loss using `criterion`, save the output to loss. \"\"\"\n",
    "        # convert shape from [batch size, 1] to [batch size]\n",
    "        y_hat = y_hat.view(y_hat.shape[0])\n",
    "        loss = criterion(y_hat, y)\n",
    "        \"\"\" Step 4. backward pass \"\"\"\n",
    "        loss.backward()\n",
    "        \"\"\" Step 5. optimization \"\"\"\n",
    "        optimizer.step()\n",
    "        \"\"\" Step 6. record loss \"\"\"\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))\n",
    "    evaluate(model, train_loader)\n",
    "    evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "💡 How many updates happen per epoch?\n",
    "\n",
    "    If train_loader gives batches of size 4 and your dataset has 100 patients,\n",
    "\n",
    "    Then:\n",
    "    100 patients / 4 per batch = 25 batches per epoch\n",
    "\n",
    "    So the weights are updated 25 times per epoch (i.e., after each batch).\n",
    "\n",
    "📌 What does \"Stochastic Gradient Descent\" really mean?\n",
    "\n",
    "    Stochastic = using a random sample of the data to estimate the gradient\n",
    "\n",
    "    That “random sample” is typically a mini-batch (not just a single row)\n",
    "\n",
    "    In PyTorch, torch.utils.data.DataLoader shuffles data & gives mini-batches\n",
    "\n",
    "🆚 What if you updated after each row (i.e. pure SGD)?\n",
    "\n",
    "    That would be very noisy and inefficient for large datasets.\n",
    "\n",
    "    Most practical implementations use mini-batch SGD, which balances efficiency and convergence stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e1bb6d002dfdde2e49da4549decf9a6",
     "grade": false,
     "grade_id": "cell-2e30120254908ff1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The result is bad due to very limited data. The model overfits the training data very fast.\n",
    "\n",
    "You are encouraged to try this on the whole MIMIC-III dataset. The result will be much more promising!"
   ]
  }
 ],
 "metadata": {
  "illinois_payload": {
   "b64z": "",
   "nb_path": "release/LAB3/LAB3.ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (Threads: 2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.1875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
